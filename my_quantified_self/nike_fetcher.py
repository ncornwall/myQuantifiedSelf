
import logging
import os
from dotenv import load_dotenv
import logging
from utils import get, post, get_json_from_file, save_json_to_file, isBlank

class NikeFetcher():
    """
    Fetches data from Nike APIs
    Nike access token can be generated by going to Nike.com and copying an access token
    from a random API call on the site
    """

    def __init__(self):
        load_dotenv(verbose=True)
        self.nike_access_token = os.getenv("NIKE_ACCESS_TOKEN")
        self.dir = "data/"
        self.activities_filename = 'data/NIKE_paginated_activity_single_list.txt'
        self.additional_activities_filename = "data/NIKE_detailed_activities.txt"

    def fetch_nike_activities(self, refresh_cache=False):
        """Fetches all Nike activities. If they are saved in a JSON file, it will use that as the source,
        otherwise will fetch all activities from the API.

        Args:
            refresh_cache (bool, optional): Will force a refresh of the data in saved JSON files. Defaults to False.
        """
        activities = get_json_from_file(self.dir, self.activities_filename)
        if activities and not refresh_cache:
            logging.info(f"Using cached activities for Nike data")
            return activities
        
        logging.info(f"Fetching new activities for Nike data")
        try:
            if isBlank(self.nike_access_token):
                raise Exception("Please provide a Nike token in order to fetch Nike data.")

            url = ("https://api.nike.com/sport/v3/me/activities/after_time/0")
            first_page = get(url, bearer_token=self.nike_access_token)
            activities = self.get_all_subsequent_nike_pages(first_page)
            save_json_to_file(self.activities_filename, activities)

            # For fun fetch all additional metrics
            self.get_nike_additional_metrics()

            return activities
        except Exception:
            logging.exception("Something went wrong, could not fetch Nike data")

    def get_all_subsequent_nike_pages(self, first_page):
        """Fetches paginated data from nike and merges the pages into a single list
        """
        all_items = []
        all_items.extend(first_page['activities'])
        this_page = first_page
        while(True):
            if 'paging' in this_page and 'after_id' in this_page['paging']:
                after_id = this_page['paging']['after_id']
                url=f"https://api.nike.com/sport/v3/me/activities/after_id/{after_id}"
                new_page = get(url, bearer_token=self.nike_access_token) 
                all_items.extend(new_page['activities'])
                this_page = new_page
            else:
                break
        return all_items

    def get_nike_additional_metrics(self):
        """
            Not using this detailed Nike data for anything.
            But it seems interesting to fetch from the API.
            While you're hacking the Nike walled garden.
        """
        detailed_activities = get_json_from_file(self.dir, self.additional_activities_filename)
        if detailed_activities:
            logging.info('Fetching nike detailed activities from file')
            return detailed_activities

        logging.info("Fetching nike detailed activities from API")
        try:
            activities = self.fetch_nike_activities()
            nike_detailed_activities = []
            for activity in activities:
                activity_id = activity['id']
                url = f"https://api.nike.com/sport/v3/me/activity/{activity_id}?metrics=ALL"
                detailed_activity = get(url, bearer_token=self.nike_access_token)
                nike_detailed_activities.append(detailed_activity)
            save_json_to_file(self.additional_activities_filename, nike_detailed_activities)
            return nike_detailed_activities
        except Exception:
            logging.exception("Something went wrong, could not fetch additional Nike data")
